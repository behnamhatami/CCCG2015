{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":15282,"databundleVersionId":565187,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preamble","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as p\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport zipfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:41:25.235095Z","iopub.execute_input":"2025-02-09T17:41:25.235593Z","iopub.status.idle":"2025-02-09T17:41:25.242008Z","shell.execute_reply.started":"2025-02-09T17:41:25.235556Z","shell.execute_reply":"2025-02-09T17:41:25.240333Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# Extract data","metadata":{}},{"cell_type":"code","source":"with zipfile.ZipFile('../input/platesv2/plates.zip', 'r') as zip_obj:\n    zip_obj.extractall('/kaggle/working/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:41:27.092537Z","iopub.execute_input":"2025-02-09T17:41:27.092948Z","iopub.status.idle":"2025-02-09T17:41:27.507400Z","shell.execute_reply.started":"2025-02-09T17:41:27.092918Z","shell.execute_reply":"2025-02-09T17:41:27.506108Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def load_images_from_folder(folder_path):\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),  # Resize images to a fixed size\n        transforms.ToTensor(),  # Convert images to tensors\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n    ])\n    \n    image_tensors = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Ensure correct image formats\n            img_path = os.path.join(folder_path, filename)\n            image = Image.open(img_path).convert('RGB')  # Convert to RGB to handle grayscale images\n            image_tensor = transform(image)\n            image_tensors.append(image_tensor)\n    \n    return torch.stack(image_tensors)  # Stack tensors into a batch\n\n# Example usage:\nfolder_path = \"/kaggle/working/plates/train/cleaned\"  # Change to your actual folder path\nc_image_tensors = load_images_from_folder(folder_path)\nfolder_path = \"/kaggle/working/plates/train/dirty\"  # Change to your actual folder path\nd_image_tensors = load_images_from_folder(folder_path)\n\nX = torch.cat([c_image_tensors, d_image_tensors], dim=0)\nY = torch.tensor([0]*20 + [1]*20)\nprint(f\"Loaded {data.shape} images with shape {c_image_tensors.shape[1:]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:41:00.789791Z","iopub.execute_input":"2025-02-09T17:41:00.790281Z","iopub.status.idle":"2025-02-09T17:41:01.014880Z","shell.execute_reply.started":"2025-02-09T17:41:00.790241Z","shell.execute_reply":"2025-02-09T17:41:01.013148Z"}},"outputs":[{"name":"stdout","text":"Loaded torch.Size([40, 3, 256, 256]) images with shape torch.Size([3, 256, 256])\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# Augment","metadata":{}}]}